# cmd="utils/queue.pl --mem 10G --gpu 1 --config conf/gpu.conf"

# ${cmd} prepare.log \
#   bash -c 'export CUDA_VISIBLE_DEVICES=$(free-gpu); /export/c07/sli218/miniconda3/envs/OVAD/bin/python3.8 ./prepare.py'
#!/usr/bin/env bash

set -eou pipefail

nj=15
stage=0
stop_stage=100

# We assume dl_dir (download dir) contains the following
# directories and files. If not, they will be downloaded
# by this script automatically.
#
#  - $dl_dir/LibriSpeech
#      You can find BOOKS.TXT, test-clean, train-clean-360, etc, inside it.
#      You can download them from https://www.openslr.org/12
#
#  - $dl_dir/lm
#      This directory contains the following files downloaded from
#       http://www.openslr.org/resources/11
#
#        - 3-gram.pruned.1e-7.arpa.gz
#        - 3-gram.pruned.1e-7.arpa
#        - 4-gram.arpa.gz
#        - 4-gram.arpa
#        - librispeech-vocab.txt
#        - librispeech-lexicon.txt
#        - librispeech-lm-norm.txt.gz
#
#  - $dl_dir/musan
#      This directory contains the following directories downloaded from
#       http://www.openslr.org/17/
#
#     - music
#     - noise
#     - speech
dl_dir=/export/corpora5

# cslu_kids_dir =/export/corpora5/LDC/LDC2007S18
# cmu_kids_dir =/export/corpora5/LDC/LDC97S63

# gale_arabic_audio_dir = /export/corpora5/LDC/LDC2013S02

# gale_arabic_text_dir = /export/corpora5/LDC/LDC2013T17

# gale_mandarin_audio_dir = [/export/corpora5/LDC/LDC2013S08,
#     /export/corpora5/LDC/LDC2013S04,
#     /export/corpora5/LDC/LDC2014S09,
#     /export/corpora5/LDC/LDC2015S06,
#     /export/corpora5/LDC/LDC2015S13,
#     /export/corpora5/LDC/LDC2016S03]

# gale_mandarin_text_dir = [/export/corpora5/LDC/LDC2013T20,
#     /export/corpora5/LDC/LDC2013T08,
#     /export/corpora5/LDC/LDC2014T28,
#     /export/corpora5/LDC/LDC2015T09,
#     /export/corpora5/LDC/LDC2016T12]

# librispeech_dir =/export/corpora5/LibriSpeech
# nsc_dir = /export/corpora5/nsc
# mtedx_dir =/export/corpora5/mTEDx
# switchboard_dir = /export/corpora5/switchboard
# tedlium_dir = /export/corpora5/TEDLIUM_release-3
    
# annotations_dir = /export/c07/sli218

    # download_ami(corpus_dir, annotations=annotations_dir, mic="sdm")
# output_dir = $PWD/exp/data


# vocab size for sentence piece models.
# It will generate data/lang_bpe_xxx,
# data/lang_bpe_yyy if the array contains xxx, yyy
vocab_sizes=(
  5000
  2000
  1000
  500
)

# All files generated by this script are saved in "data".
# You can safely remove "data" and rerun this script to regenerate it.
mkdir -p data

log() {
  # This function is from espnet
  local fname=${BASH_SOURCE[1]##*/}
  echo -e "$(date '+%Y-%m-%d %H:%M:%S') (${fname}:${BASH_LINENO[0]}:${FUNCNAME[1]}) $*"
}

log "dl_dir: $dl_dir"

# if [ $stage -le -1 ] && [ $stop_stage -ge -1 ]; then
#   log "Stage -1: Download LM"
#   mkdir -p $dl_dir/lm
#   if [ ! -e $dl_dir/lm/.done ]; then
#     ./local/download_lm.py --out-dir=$dl_dir/lm
#     touch $dl_dir/lm/.done
#   fi
# fi

if [ $stage -le 0 ] && [ $stop_stage -ge 0 ]; then
  log "Stage 0: Download data"

  # If you have pre-downloaded it to /path/to/LibriSpeech,
  # you can create a symlink
  #
  #   ln -sfv /path/to/LibriSpeech $dl_dir/LibriSpeech
  #
  # if [ ! -d $dl_dir/LibriSpeech/train-other-500 ]; then
  #   lhotse download librispeech --full $dl_dir
  # fi

  # If you have pre-downloaded it to /path/to/musan,
  # you can create a symlink
  #
  #   ln -sfv /path/to/musan $dl_dir/
  #
  # if [ ! -d $dl_dir/musan ]; then
  #   lhotse download musan $dl_dir
  # fi
fi

if [ $stage -le 1 ] && [ $stop_stage -ge 1 ]; then
  log "Stage 1: Prepare AMI manifest"
  # We assume that you have downloaded the LibriSpeech corpus
  # to $dl_dir/LibriSpeech
  annotations_dir=/export/c07/sli218/kaldi/egs
  mkdir -p data/manifests
  if [ ! -e data/manifests/.ami.done ]; then
    lhotse prepare ami $dl_dir/amicorpus data/manifests
    touch data/manifests/.ami.done
  fi
fi

if [ $stage -le 2 ] && [ $stop_stage -ge 2 ]; then
  log "Stage 2: Prepare librispeech manifest"
  # We assume that you have downloaded the musan corpus
  # to data/musan
  mkdir -p data/manifests
  if [ ! -e data/manifests/.librispeech.done ]; then
    lhotse prepare librispeech -j $nj $dl_dir/LibriSpeech data/manifests
    touch data/manifests/.librispeech.done
  fi
fi

if [ $stage -le 3 ] && [ $stop_stage -ge 3 ]; then
  log "Stage 3: Prepare cmu kids manifest"
  mkdir -p data/manifests
  if [ ! -e data/manifests/.cmu_kids.done ]; then
    lhotse prepare cmu-kids $dl_dir/LDC/LDC97S63 data/manifests
    touch data/manifests/.cmu_kids.done
  fi
fi

if [ $stage -le 4 ] && [ $stop_stage -ge 4 ]; then
  log "Stage 4: Prepare cslu kids manifest"
  mkdir -p data/manifests
  if [ ! -e data/manifests/.cslu-kids.done ]; then
    lhotse prepare cslu-kids $dl_dir/LDC/LDC2007S18 data/manifests
    touch data/manifests/.cslu-kids.done
  fi
fi

if [ $stage -le 5 ] && [ $stop_stage -ge 5 ]; then
  log "Stage 5: Prepare gale arabic manifest"
  mkdir -p data/manifests
  if [ ! -e data/manifests/.gale_arabic.done ]; then
    # lhotse prepare gale-arabic \
    #   -s $dl_dir/LDC/LDC2013S02 \
    #   -t $dl_dir/LDC/LDC2013T17 data/manifests
    touch data/manifests/.gale_arabic.done
  fi
fi


if [ $stage -le 6 ] && [ $stop_stage -ge 6 ]; then
  log "Stage 6: Prepare gale mandarin manifest"
  mkdir -p data/manifests
  if [ ! -e data/manifests/.gale_mandarin.done ]; then
    lhotse prepare gale-mandarin \
    -s $dl_dir/LDC/LDC2013S08 \
    -s $dl_dir/LDC/LDC2013S04 \
    -s $dl_dir/LDC/LDC2014S09 \
    -s $dl_dir/LDC/LDC2015S06 \
    -s $dl_dir/LDC/LDC2015S13 \
    -s $dl_dir/LDC/LDC2016S03 \
    -t $dl_dir/LDC/LDC2013T20 \
    -t $dl_dir/LDC/LDC2013T08 \
    -t $dl_dir/LDC/LDC2014T28 \
    -t $dl_dir/LDC/LDC2015T09 \
    -t $dl_dir/LDC/LDC2015T25 \
    -t $dl_dir/LDC/LDC2016T12 data/manifests
    touch data/manifests/.gale_mandarin.done
  fi
fi

if [ $stage -le 7 ] && [ $stop_stage -ge 7 ]; then
  log "Stage 7: Prepare nsc manifest"

  mkdir -p data/manifests
  if [ ! -e data/manifests/.nsc.done ]; then
    lhotse prepare nsc $dl_dir/nsc data/manifests
    touch data/manifests/.nsc.done
  fi
fi

if [ $stage -le 8 ] && [ $stop_stage -ge 8 ]; then
  log "Stage 8: Prepare mtedx manifest"

  mkdir -p data/manifests
  if [ ! -e data/manifests/.mtedx.done ]; then
    lhotse prepare mtedx $dl_dir/mTEDx data/manifests
    touch data/manifests/.mtedx.done
  fi
fi

if [ $stage -le 9 ] && [ $stop_stage -ge 9 ]; then
  log "Stage 9: Prepare tedlium manifest"

  mkdir -p data/manifests
  if [ ! -e data/manifests/.tedlium.done ]; then
    lhotse prepare tedlium $dl_dir/TEDLIUM_release-3 data/manifests
    touch data/manifests/.tedlium.done
  fi
fi

if [ $stage -le 10 ] && [ $stop_stage -ge 10 ]; then
  log "Stage 10: compute fbank for all datasets"
  mkdir -p data/fbank
  if [ ! -e data/fbank/.librispeech.done ]; then
    ./local/compute_fbank_librispeech.py
    touch data/fbank/.librispeech.done
  fi
  if [ ! -e data/fbank/.tedlium.done ]; then
    # ./local/compute_fbank_tedlium.py
    touch data/fbank/.tedlium.done
  fi
  # if [ ! -e data/fbank/.nsc.done ]; then
  #   ./local/compute_fbank_nsc.py
  #   touch data/fbank/.nsc.done
  # fi
  # if [ ! -e data/fbank/.cmu_kids.done ]; then
  #   ./local/compute_fbank_cmu_kids.py
  #   touch data/fbank/.cmu_kids.done
  # fi
  # if [ ! -e data/fbank/.cslu_kids.done ]; then
  #   ./local/compute_fbank_cslu_kids.py
  #   touch data/fbank/.cslu_kids.done
  # fi
  # if [ ! -e data/fbank/.gale_manderin.done ]; then
  #   ./local/compute_fbank_gale_manderin.py
  #   touch data/fbank/.gale_manderin.done
  # fi
  # if [ ! -e data/fbank/.ami.done ]; then
  #   ./local/compute_fbank_ami.py
  #   touch data/fbank/.ami.done
  # fi
  
  
fi

if [ $stage -le 11 ] && [ $stop_stage -ge 11 ]; then
  log "Stage 11: Combine manifests for all datasets"
  mkdir -p data/fbank
  if [ ! -f data/fbank/universal_vad_dev.jsonl.gz ]; then
    pieces=$(find data/fbank -name "*dev*jsonl.gz")
    echo $pieces
    lhotse combine $pieces data/fbank/universal_vad_dev.jsonl.gz
  fi
  if [ ! -f data/fbank/universal_vad_train.jsonl.gz ]; then
    pieces=$(find data/fbank -name "*train*jsonl.gz")
    echo $pieces
    lhotse combine $pieces data/fbank/universal_vad_train.jsonl.gz
  fi
  if [ ! -f data/fbank/universal_vad_test.jsonl.gz ]; then
    pieces=$(find data/fbank -name "*test*jsonl.gz")
    echo $pieces
    lhotse combine $pieces data/fbank/universal_vad_test.jsonl.gz
  fi
fi



if [ $stage -le 12 ] && [ $stop_stage -ge 12 ]; then
  log "Stage 12: Generate LM validation data"

  for vocab_size in ${vocab_sizes[@]}; do
    log "Processing vocab_size == ${vocab_size}"
    out_dir=data/lm_training_bpe_${vocab_size}
    mkdir -p $out_dir

    if [ ! -f $out_dir/valid.txt ]; then
      files=$(
        find "$dl_dir/LibriSpeech/dev-clean" -name "*.trans.txt"
        find "$dl_dir/LibriSpeech/dev-other" -name "*.trans.txt"
      )
      for f in ${files[@]}; do
        cat $f | cut -d " " -f 2-
      done > $out_dir/valid.txt
    fi

    lang_dir=data/lang_bpe_${vocab_size}
    ./local/prepare_lm_training_data.py \
      --bpe-model $lang_dir/bpe.model \
      --lm-data $out_dir/valid.txt \
      --lm-archive $out_dir/lm_data-valid.pt
  done
fi

if [ $stage -le 13 ] && [ $stop_stage -ge 13 ]; then
  log "Stage 13: Generate LM test data"

  for vocab_size in ${vocab_sizes[@]}; do
    log "Processing vocab_size == ${vocab_size}"
    out_dir=data/lm_training_bpe_${vocab_size}
    mkdir -p $out_dir

    if [ ! -f $out_dir/test.txt ]; then
      files=$(
        find "$dl_dir/LibriSpeech/test-clean" -name "*.trans.txt"
        find "$dl_dir/LibriSpeech/test-other" -name "*.trans.txt"
      )
      for f in ${files[@]}; do
        cat $f | cut -d " " -f 2-
      done > $out_dir/test.txt
    fi

    lang_dir=data/lang_bpe_${vocab_size}
    ./local/prepare_lm_training_data.py \
      --bpe-model $lang_dir/bpe.model \
      --lm-data $out_dir/test.txt \
      --lm-archive $out_dir/lm_data-test.pt
  done
fi

if [ $stage -le 14 ] && [ $stop_stage -ge 14 ]; then
  log "Stage 14: Sort LM training data"
  # Sort LM training data by sentence length in descending order
  # for ease of training.
  #
  # Sentence length equals to the number of BPE tokens
  # in a sentence.

  for vocab_size in ${vocab_sizes[@]}; do
    out_dir=data/lm_training_bpe_${vocab_size}
    mkdir -p $out_dir
    ./local/sort_lm_training_data.py \
      --in-lm-data $out_dir/lm_data.pt \
      --out-lm-data $out_dir/sorted_lm_data.pt \
      --out-statistics $out_dir/statistics.txt

    ./local/sort_lm_training_data.py \
      --in-lm-data $out_dir/lm_data-valid.pt \
      --out-lm-data $out_dir/sorted_lm_data-valid.pt \
      --out-statistics $out_dir/statistics-valid.txt

    ./local/sort_lm_training_data.py \
      --in-lm-data $out_dir/lm_data-test.pt \
      --out-lm-data $out_dir/sorted_lm_data-test.pt \
      --out-statistics $out_dir/statistics-test.txt
  done
fi